{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import imageio\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Flatten, Dense, Convolution2D, Lambda, BatchNormalization, Dropout\n",
    "from keras import backend as K\n",
    "from sklearn.utils import shuffle as sk_shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_samples(data_path,\n",
    "                 csv_file_name='driving_log.csv',\n",
    "                 samples=[],\n",
    "                 correction_left=0.23,\n",
    "                 correction_right=0.27,\n",
    "                 drop_prob=0.7):\n",
    "    \"\"\"\n",
    "    Loads all the samples in the a single list. Does not load the image, but sets the correct path\n",
    "    so they can be loaded by the generators.\n",
    "\n",
    "    Args:\n",
    "        data_path: str: The path to the data directory with the slash at the end\n",
    "        csv_file_name: str: The name of csv_file that should be used.\n",
    "        samples: list: The list of samples, starts with empty one.\n",
    "        correction_left: float: The correction that should be used for the left image\n",
    "        correct_right: float: The correction that should be applied for the right image\n",
    "\n",
    "    Returns:\n",
    "        samples: list: The list of samples with only one image path and the value of steering\n",
    "    \"\"\"\n",
    "    csv_file_path = str(data_path) + str(csv_file_name)\n",
    "    image_path = str(data_path) + \"IMG/\"\n",
    "    with open(csv_file_path) as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        for line in reader:\n",
    "            for i in range(3):\n",
    "                file_name = get_file_name(line[i])\n",
    "                file_path = str(image_path) + str(file_name)\n",
    "                basic_steering = float(line[3])\n",
    "                # Drop the streing that is negative or zero with probability of 0.7\n",
    "                if basic_steering == 0 and np.random.rand() < drop_prob:\n",
    "                    continue\n",
    "                data = [file_path]\n",
    "                if i == 0:\n",
    "                    data.append(basic_steering)\n",
    "                if i == 1:\n",
    "                    data.append(basic_steering + correction_left)\n",
    "                if i == 2:\n",
    "                    data.append(basic_steering - correction_right)\n",
    "                samples.append(data)\n",
    "    return samples\n",
    "\n",
    "\n",
    "def read_image(image_path):\n",
    "    \"\"\"\n",
    "    Reads the image to the given array\n",
    "\n",
    "    Args:\n",
    "        image_path: str: The path to the image file that should be read\n",
    "\n",
    "    Returns:\n",
    "        image: list: The array like image or PIL image\n",
    "\n",
    "    \"\"\"\n",
    "    return imageio.imread(image_path)\n",
    "\n",
    "\n",
    "def flip_image(image, basic_steering):\n",
    "    \"\"\"\n",
    "    Flips the image\n",
    "\n",
    "    Args:\n",
    "        image: list: The array like image or PIL image\n",
    "        basic_steering: float: The basic steering value\n",
    "\n",
    "    Returns:\n",
    "        flipped_image: list: The array like image or PIL image\n",
    "        basic_steering_flipped: float: The basic steering value for flipped image\n",
    "    \"\"\"\n",
    "    image_flipped = np.fliplr(image)\n",
    "    basic_steering_flipped = - basic_steering\n",
    "    return image_flipped, basic_steering_flipped\n",
    "\n",
    "\n",
    "def get_file_name(file_field=\"\"):\n",
    "    \"\"\"\n",
    "    Returns the file name for the given field\n",
    "\n",
    "    Args:\n",
    "        file_field: str: The file field for the given file\n",
    "\n",
    "    Returns:\n",
    "        str: The name of the file in the field\n",
    "    \"\"\"\n",
    "    return file_field.split('/')[-1]\n",
    "\n",
    "\n",
    "def generator(samples, batch_size=32, with_flipped=True):\n",
    "    \"\"\"\n",
    "    Generates the needed images in the given batch size\n",
    "\n",
    "    Args:\n",
    "        samples: list: The complete list of samples that should be used\n",
    "        batch_size: int: The size of batches that should be used\n",
    "        with_flipped: bool: Should the flipped images also be used.\n",
    "\n",
    "    Yields:\n",
    "\n",
    "        X_train, the images for the training\n",
    "        y_train, the labels for the training\n",
    "    \"\"\"\n",
    "    num_samples = len(samples)\n",
    "    # Always\n",
    "    while 1:\n",
    "        sk_shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            measurements = []\n",
    "            for batch_sample in batch_samples:\n",
    "                # Add the main image\n",
    "                image = read_image(batch_sample[0])\n",
    "                measurement = batch_sample[1]\n",
    "                images.append(image)\n",
    "                measurements.append(measurement)\n",
    "                # Flipped image\n",
    "                if with_flipped:\n",
    "                    flipped, steering = flip_image(image, measurement)\n",
    "                    images.append(flipped)\n",
    "                    measurements.append(steering)\n",
    "\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(measurements)\n",
    "            yield sk_shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Samples:  27219\n"
     ]
    }
   ],
   "source": [
    "# Load the data as samples\n",
    "# data_2 is my own recorded data\n",
    "# data is the provided data from udacity\n",
    "\n",
    "samples = load_samples('data_2/', samples=[])\n",
    "samples = load_samples('data/', samples=samples)\n",
    "print('All Samples: ', len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 21775\n",
      "Validation Samples:  5444\n"
     ]
    }
   ],
   "source": [
    "# Create the needed sets\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "print('Training Samples:', len(train_samples))\n",
    "print('Validation Samples: ', len(validation_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generators\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nvidia Model\n",
    "def create_training_model(drop_prob=0.5, input_shape=(160, 320, 3), learning_rate=0.0009):\n",
    "    \"\"\"\n",
    "    Creates the training with help of Keras\n",
    "\n",
    "    Args:\n",
    "        drop_prob: float: The dropout probability\n",
    "        input_shape: tuple: The shape of the input image, defaults to (160,320,3)\n",
    "        learning_rate: float: The value of training_loss that is 0.0009\n",
    "\n",
    "    Return:\n",
    "        model: The sequential model that is created with keras\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x - 255.0 / 255.0, input_shape=input_shape))\n",
    "    model.add(BatchNormalization(axis=3))\n",
    "    model.add(Convolution2D(24, (5, 5), strides=(2, 2), activation='relu'))\n",
    "    model.add(Convolution2D(36, (5, 5), strides=(2, 2), activation='relu'))\n",
    "    model.add(Convolution2D(48, (5, 5), strides=(2, 2), activation='relu'))\n",
    "    model.add(BatchNormalization(axis=3))\n",
    "    model.add(Convolution2D(64, (3, 3), strides=(1, 1), activation='relu'))\n",
    "    model.add(Convolution2D(64, (3, 3), strides=(1, 1), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(drop_prob))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(drop_prob))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=learning_rate))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 160, 320, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 78, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 37, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 17, 37, 48)        43248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 17, 37, 48)        192       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 35, 64)        27712     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 33, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 27456)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               2745700   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,883,463\n",
      "Trainable params: 2,883,041\n",
      "Non-trainable params: 422\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Add the model data and fitting\n",
    "model = create_training_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "680/680 [==============================] - 167s 245ms/step - loss: 0.2824 - val_loss: 0.0968\n",
      "Epoch 2/7\n",
      "680/680 [==============================] - 164s 241ms/step - loss: 0.1042 - val_loss: 0.0738\n",
      "Epoch 3/7\n",
      "680/680 [==============================] - 155s 228ms/step - loss: 0.0792 - val_loss: 0.0563\n",
      "Epoch 4/7\n",
      "680/680 [==============================] - 156s 229ms/step - loss: 0.0670 - val_loss: 0.0524\n",
      "Epoch 5/7\n",
      "680/680 [==============================] - 154s 226ms/step - loss: 0.0603 - val_loss: 0.0505\n",
      "Epoch 6/7\n",
      "680/680 [==============================] - 154s 226ms/step - loss: 0.0549 - val_loss: 0.0509\n",
      "Epoch 7/7\n",
      "680/680 [==============================] - 154s 226ms/step - loss: 0.0524 - val_loss: 0.0434\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=int(len(train_samples)/batch_size),\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=int(len(validation_samples)/batch_size),\n",
    "                    epochs=7)\n",
    "model.save('nvidia_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty the memory of GPU\n",
    "K.clear_session()\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
